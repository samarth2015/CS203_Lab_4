{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Setup the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the MNIST dataset using the Hugging Face datasets library.\n",
    "- Convert the image data into Numpy arrays and normalize pixel values to the range [0,1].\n",
    "- Flatten each image into a vector of 784 features.\n",
    "- Split the dataset into training and testing sets.\n",
    "- Randomly select an initially labeled dataset of 200 samples from training samples.\n",
    "- Generate an \"Unlabeled Pool,\" the Initial Dataset excluding 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image data into a numpy array and normalize the values from 0 to 1\n",
    "X = np.array(data['train'][\"image\"]) / 255\n",
    "y = np.array(data['train'][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(data['test'][\"image\"]) / 255\n",
    "y_test = np.array(data['test'][\"label\"])\n",
    "\n",
    "# flatten the test data\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 200 samples from training dataset and create a labelled dataset\n",
    "np.random.seed(45)   \n",
    "idx = np.random.choice(X.shape[0], 200, replace=False)\n",
    "X_train_labelled = X[idx]\n",
    "y_train_labelled = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59800, 784)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pool of unlabelled data\n",
    "X_train_unlabelled = np.delete(X, idx, axis=0)\n",
    "y_train_unlabelled = np.delete(y, idx, axis=0)\n",
    "\n",
    "X_train_unlabelled.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement Random Sampling for Active Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a Random Forest Classifier (you can use “from sklearn.ensemble import RandomForestClassifier”)  on the initial dataset of 200 samples.\n",
    "- Implement an active learning loop for 20 iterations:\n",
    "    - Randomly select a sample from the unlabeled pool.\n",
    "    - Get the selected sample and its true label.\n",
    "    - Add the sample and label to the labeled dataset.\n",
    "    - Remove the selected sample and label from the pool.\n",
    "    - Retrain the model on the updated dataset.\n",
    "    - Check the model's accuracy on the test set.\n",
    "    - Print accuracy after every iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7832"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# train a random forest classifier on the labelled data\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "# predict the unlabelled data\n",
    "y_prediction = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the classifier\n",
    "accuracy = np.mean(y_test == y_prediction)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Accuracy: 0.7853\n",
      "Iteration: 1 Accuracy: 0.7874\n",
      "Iteration: 2 Accuracy: 0.7861\n",
      "Iteration: 3 Accuracy: 0.7812\n",
      "Iteration: 4 Accuracy: 0.7773\n",
      "Iteration: 5 Accuracy: 0.7837\n",
      "Iteration: 6 Accuracy: 0.7889\n",
      "Iteration: 7 Accuracy: 0.7809\n",
      "Iteration: 8 Accuracy: 0.7792\n",
      "Iteration: 9 Accuracy: 0.7923\n",
      "Iteration: 10 Accuracy: 0.8031\n",
      "Iteration: 11 Accuracy: 0.7882\n",
      "Iteration: 12 Accuracy: 0.7897\n",
      "Iteration: 13 Accuracy: 0.7946\n",
      "Iteration: 14 Accuracy: 0.8058\n",
      "Iteration: 15 Accuracy: 0.7948\n",
      "Iteration: 16 Accuracy: 0.7958\n",
      "Iteration: 17 Accuracy: 0.7903\n",
      "Iteration: 18 Accuracy: 0.7905\n",
      "Iteration: 19 Accuracy: 0.801\n"
     ]
    }
   ],
   "source": [
    "# implementing active learning by for 20 iterations by randomly choosing the samples from the unlabelled pool.\n",
    "task1_results = []\n",
    "for i in range(20):\n",
    "    idx_curr = np.random.choice(X_train_unlabelled.shape[0], 1, replace=False) # randomly select 1 sample\n",
    "    \n",
    "    # add the sample to the labelled dataset\n",
    "    X_train_labelled = np.concatenate([X_train_labelled, X_train_unlabelled[idx_curr]])\n",
    "    y_train_labelled = np.concatenate([y_train_labelled, y_train_unlabelled[idx_curr]])\n",
    "\n",
    "    # remove the sample from the unlabelled dataset\n",
    "    X_train_unlabelled = np.delete(X_train_unlabelled, idx_curr, axis=0)\n",
    "    y_train_unlabelled = np.delete(y_train_unlabelled, idx_curr, axis=0)\n",
    "\n",
    "    # retrain the classifier\n",
    "    clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "    # predict the unlabelled data\n",
    "    y_prediction= clf.predict(X_test)\n",
    "\n",
    "    # calculate the accuracy of the classifier\n",
    "    accuracy = np.mean(y_test == y_prediction)\n",
    "    task1_results.append(accuracy)\n",
    "    print(f\"Iteration: {i} Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement Uncertainty Sampling for Active Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a Random Forest Classifier (you can use “from sklearn.ensemble import RandomForestClassifier”)  on the initial dataset of 200 samples.\n",
    "- Implement an active learning loop for 20 iterations:\n",
    "    - Compute uncertainty (Label Entropy) for each sample in the unlabeled pool using entropy.\n",
    "    - Select the sample with the highest uncertainty and query its true label.\n",
    "    - Add the queried sample to the labelled dataset and remove it from the unlabelled pool.\n",
    "    - Retrain the model and check the model's accuracy on the test set.\n",
    "    - Print accuracy after every iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(45)   \n",
    "idx = np.random.choice(X.shape[0], 200, replace=False)\n",
    "X_train_labelled = X[idx]\n",
    "y_train_labelled = y[idx]\n",
    "\n",
    "X_train_unlabelled=np.delete(X,idx,axis=0)\n",
    "y_train_unlabelled=np.delete(y,idx,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59800, 784)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unlabelled.shape\n",
    "# Y_train_unlabelled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_labelled,y_train_labelled)\n",
    "y_prediction=clf.predict(X_test)\n",
    "accuracy=np.mean(y_test==y_prediction)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelentropy(probability):\n",
    "    max_entropy=float('-inf')\n",
    "    epsilon=1e-10\n",
    "    maxind=-1\n",
    "    for i in range(len(probability)):\n",
    "        ent=np.sum(probability[i]*np.log10(probability[i]+epsilon))\n",
    "        if(ent>max_entropy):\n",
    "            max_entropy=ent\n",
    "            maxind=i\n",
    "    return [maxind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unlabelled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Accuracy: 0.7699\n",
      "Iteration: 1 Accuracy: 0.7744\n",
      "Iteration: 2 Accuracy: 0.7807\n",
      "Iteration: 3 Accuracy: 0.7801\n",
      "Iteration: 4 Accuracy: 0.7611\n",
      "Iteration: 5 Accuracy: 0.7688\n",
      "Iteration: 6 Accuracy: 0.7837\n",
      "Iteration: 7 Accuracy: 0.7731\n",
      "Iteration: 8 Accuracy: 0.7772\n",
      "Iteration: 9 Accuracy: 0.7812\n",
      "Iteration: 10 Accuracy: 0.7809\n",
      "Iteration: 11 Accuracy: 0.7691\n",
      "Iteration: 12 Accuracy: 0.7674\n",
      "Iteration: 13 Accuracy: 0.7763\n",
      "Iteration: 14 Accuracy: 0.7677\n",
      "Iteration: 15 Accuracy: 0.7733\n",
      "Iteration: 16 Accuracy: 0.7766\n",
      "Iteration: 17 Accuracy: 0.7874\n",
      "Iteration: 18 Accuracy: 0.7742\n",
      "Iteration: 19 Accuracy: 0.7797\n"
     ]
    }
   ],
   "source": [
    "task2_results=[]\n",
    "for i in range(20):\n",
    "    probability=clf.predict_proba(X_train_unlabelled)\n",
    "    idx_curr=labelentropy(probability)\n",
    "    \n",
    "    # add the sample to the labelled dataset\n",
    "    X_train_labelled = np.concatenate([X_train_labelled, X_train_unlabelled[idx_curr]])\n",
    "    y_train_labelled = np.concatenate([y_train_labelled, y_train_unlabelled[idx_curr]])\n",
    "\n",
    "    # remove the sample from the unlabelled dataset\n",
    "    X_train_unlabelled = np.delete(X_train_unlabelled, idx_curr, axis=0)\n",
    "    y_train_unlabelled = np.delete(y_train_unlabelled, idx_curr, axis=0)\n",
    "\n",
    "    # retrain the classifier\n",
    "    clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "    # predict the unlabelled data\n",
    "    y_prediction= clf.predict(X_test)\n",
    "\n",
    "    # calculate the accuracy of the classifier\n",
    "    accuracy = np.mean(y_test == y_prediction)\n",
    "    task2_results.append(accuracy)\n",
    "    print(f\"Iteration: {i} Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Implement Query-by-Committee for Active Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(45)   \n",
    "idx = np.random.choice(X.shape[0], 200, replace=False)\n",
    "X_train_labelled = X[idx]\n",
    "y_train_labelled = y[idx]\n",
    "\n",
    "X_train_unlabelled=np.delete(X,idx,axis=0)\n",
    "y_train_unlabelled=np.delete(y,idx,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_labelled,y_train_labelled)\n",
    "y_prediction=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=RandomForestClassifier(n_estimators=100)\n",
    "clf1.fit(X_train_labelled,y_train_labelled)\n",
    "y_prediction=clf1.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=RandomForestClassifier(n_estimators=100)\n",
    "clf2.fit(X_train_labelled,y_train_labelled)\n",
    "y_prediction=clf2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=RandomForestClassifier(n_estimators=100)\n",
    "clf3.fit(X_train_labelled,y_train_labelled)\n",
    "y_prediction=clf3.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4=RandomForestClassifier(n_estimators=100)\n",
    "clf4.fit(X_train_labelled,y_train_labelled)\n",
    "y_prediction=clf4.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59800\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_unlabelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voteentropy(X_train_unlabelled, clf, clf1, clf2, clf3, clf4):\n",
    "    # Stack the predictions from all classifiers into a 2D array\n",
    "    predictions = np.array([\n",
    "        clf.predict(X_train_unlabelled),\n",
    "        clf1.predict(X_train_unlabelled),\n",
    "        clf2.predict(X_train_unlabelled),\n",
    "        clf3.predict(X_train_unlabelled),\n",
    "        clf4.predict(X_train_unlabelled)\n",
    "    ])\n",
    "\n",
    "    # Transpose predictions to have shape (5, n_samples)\n",
    "    predictions = predictions.T  # Now shape is (n_samples, 5)\n",
    "\n",
    "    # Initialize an empty array for storing probabilities\n",
    "    prob = np.zeros((predictions.shape[0], 10))\n",
    "\n",
    "    # Add 0.2 for each prediction in the corresponding class\n",
    "    for i in range(predictions.shape[0]):\n",
    "        np.add.at(prob[i], predictions[i], 0.2)\n",
    "\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Accuracy: 0.793\n",
      "Iteration: 1 Accuracy: 0.7855\n",
      "Iteration: 2 Accuracy: 0.7936\n",
      "Iteration: 3 Accuracy: 0.7962\n",
      "Iteration: 4 Accuracy: 0.7953\n",
      "Iteration: 5 Accuracy: 0.7865\n",
      "Iteration: 6 Accuracy: 0.7866\n",
      "Iteration: 7 Accuracy: 0.8018\n",
      "Iteration: 8 Accuracy: 0.789\n",
      "Iteration: 9 Accuracy: 0.7871\n",
      "Iteration: 10 Accuracy: 0.8024\n",
      "Iteration: 11 Accuracy: 0.7936\n",
      "Iteration: 12 Accuracy: 0.7929\n",
      "Iteration: 13 Accuracy: 0.7934\n",
      "Iteration: 14 Accuracy: 0.7932\n",
      "Iteration: 15 Accuracy: 0.794\n",
      "Iteration: 16 Accuracy: 0.8002\n",
      "Iteration: 17 Accuracy: 0.807\n",
      "Iteration: 18 Accuracy: 0.791\n",
      "Iteration: 19 Accuracy: 0.798\n"
     ]
    }
   ],
   "source": [
    "task4_results=[]\n",
    "for i in range(20):\n",
    "    probability=voteentropy(X_train_unlabelled,clf,clf1,clf2,clf3,clf4)\n",
    "    idx_curr=labelentropy(probability)\n",
    "    \n",
    "    # add the sample to the labelled dataset\n",
    "    X_train_labelled = np.concatenate([X_train_labelled, X_train_unlabelled[idx_curr]])\n",
    "    y_train_labelled = np.concatenate([y_train_labelled, y_train_unlabelled[idx_curr]])\n",
    "\n",
    "    # remove the sample from the unlabelled dataset\n",
    "    X_train_unlabelled = np.delete(X_train_unlabelled, idx_curr, axis=0)\n",
    "    y_train_unlabelled = np.delete(y_train_unlabelled, idx_curr, axis=0)\n",
    "\n",
    "    # retrain the classifier\n",
    "    clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "    # predict the unlabelled data\n",
    "    y_prediction= clf.predict(X_test)\n",
    "\n",
    "    # calculate the accuracy of the classifier\n",
    "    accuracy = np.mean(y_test == y_prediction)\n",
    "    task4_results.append(accuracy)\n",
    "    print(f\"Iteration: {i} Accuracy: {accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
